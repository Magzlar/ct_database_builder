Aim will be to build an python app that downloads a list of study field values from a specific disease area then we use the completetion date as the label and all other 
fields will become features to train the model to predict approval date

Filters we will use to retirve studies to get an ideal trainning dataset:
- Completed
- Started => 2012
- EU or USA
- Industry funded

Label we are trying to predict = PrimaryCompletionDate

features to train on (field name as appears on CT gov API):

- Condition
- InterventionType
- Phases
- EnrollmentCount
- PrimaryOutcomeMeasure
- PrimaryOutcomeTimeFrame
- NumPrimaryOutcomes
- OrgFullName 
- StartDate
- PrimaryCompletionDate

* Potential other features (more difficult to acquire or work with):

- Market cap of org (this will have to be pulled from a stocks and shares API, and updated dynamically, perhaps monthly)
- Regulatory Designations e.g. orphan disease, Breakthrough therapy, label expansion, FastTrack (will have to be obtained from elsewhere)
- Number of study locations (will be the length of the locations list returned, but need logic to make sure all the values are unique)
- Approval status (would need to be pulled from another source, might be difficult to find, so might need to make a list for each disease manually)


Information on CT gov API:
- See https://clinicaltrials.gov/data-api/api for notes on parameters 
- See https://classic.clinicaltrials.gov/api/info/study_fields_list for notes on study field names

Example dictonary for storage using NCTid as index:
studies_data = {
    'nct00001': {"company": "Abbvie", "enrollment_count": 200, "sponsor_type": "Industry"},
    'nct00002': {"company": "Pfizer", "enrollment_count": 345, "sponsor_type": "Industry"},
    etc...
}

V2 will store the python dictionary in a local SQL database from efficant data retirve and circumvent the daily retrival limit from CT API